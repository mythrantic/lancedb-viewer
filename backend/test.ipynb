{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any, Union\n",
    "from pydantic import BaseModel\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "import pandas as pd\n",
    "from lancedb.embeddings.utils import api_key_not_found_help\n",
    "from lancedb.embeddings.registry import register\n",
    "from lancedb.embeddings import TextEmbeddingFunction, get_registry\n",
    "import numpy as np\n",
    "from functools import cached_property\n",
    "from openai import AzureOpenAI\n",
    "from azure_openai.setup import AzureOpenAiConfig\n",
    "import nest_asyncio\n",
    "import lancedb\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import logging\n",
    "import asyncio\n",
    "import sys\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "# Add parent directory to path\n",
    "current_dir = os.path.dirname(os.path.abspath(__name__))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LanceDBManager\n",
    "\n",
    "IT is responsible for all interactions with the blob storage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before that we need a lancedb embedder.\n",
    "\n",
    "### LanceDBEmbedder\n",
    "\n",
    "It is responsible for all interactions with the tables.\n",
    "there is a built in one but it had issues and could not be used. luckily we could make a custom one.\n",
    "\n",
    "the problem with the built in one is that it does not support the following:\n",
    "\n",
    "- microsoft ad authentication for enterprises\n",
    "\n",
    "it worked fine for a normal user if you dint have to go through azure ad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "openai_config = AzureOpenAiConfig()\n",
    "credentials = DefaultAzureCredential()\n",
    "token_provdier = openai_config.get_token_provider(DefaultAzureCredential())\n",
    "\n",
    "# make the custom embedder function caus ethe one provided by lancedb is not working\n",
    "\n",
    "\n",
    "@register(\"azure_openai\")\n",
    "class AzureOpenAIEmbeddings(TextEmbeddingFunction):\n",
    "    \"\"\"\n",
    "    An embedding function that uses the Azure OpenAI API\n",
    "    \"\"\"\n",
    "\n",
    "    name: str = openai_config.text_embedder_lagre.deployment_name\n",
    "    azure_api_key: str = openai_config.get_openai_api_key(\n",
    "        credential=credentials)\n",
    "    azure_endpoint: str = openai_config.endpoint\n",
    "    azure_deployment: str = openai_config.text_embedder_lagre.deployment_name\n",
    "    azure_api_version: str = openai_config.text_embedder_lagre.api_version\n",
    "\n",
    "    def ndims(self):\n",
    "        return self._ndims\n",
    "\n",
    "    @cached_property\n",
    "    def _ndims(self):\n",
    "        if self.name == openai_config.text_embedder_lagre.deployment_name:\n",
    "            return openai_config.text_embedder_lagre.ndims\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model name {self.name}\")\n",
    "\n",
    "    def ndims(self):\n",
    "        \"\"\"\n",
    "        Return the dimensionality of the embeddings.\n",
    "        \"\"\"\n",
    "        if self.name == openai_config.text_embedder_lagre.deployment_name:\n",
    "            return self._ndims\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model name {self.name}\")\n",
    "\n",
    "    def generate_embeddings(\n",
    "        self, texts: Union[List[str], np.ndarray]\n",
    "    ) -> List[np.array]:\n",
    "        \"\"\"\n",
    "        Get the embeddings for the given texts\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        texts: list[str] or np.ndarray (of str)\n",
    "            The texts to embed\n",
    "        \"\"\"\n",
    "        # TODO retry, rate limit, token limit\n",
    "        if self.name == openai_config.text_embedder_lagre.deployment_name:\n",
    "            rs = self._azure_openai_client.embeddings.create(\n",
    "                input=texts, model=self.name)\n",
    "        else:\n",
    "            rs = self._azure_openai_client.embeddings.create(\n",
    "                input=texts, model=self.name, dimensions=self.ndims()\n",
    "            )\n",
    "        return [v.embedding for v in rs.data]\n",
    "\n",
    "    @cached_property\n",
    "    def _azure_openai_client(self):\n",
    "        if not os.environ.get(\"OPENAI_API_KEY\") and not self.azure_api_key:\n",
    "            api_key_not_found_help(\"openai\")\n",
    "        return AzureOpenAI(\n",
    "            azure_endpoint=openai_config.endpoint,\n",
    "            # azure_ad_token_provider=token_provdier,\n",
    "            api_version=openai_config.api_version,\n",
    "            api_key=openai_config.get_openai_api_key(DefaultAzureCredential()),\n",
    "            max_retries=5,\n",
    "        )\n",
    "\n",
    "\n",
    "embedder = get_registry().get(\"azure_openai\").create()\n",
    "\n",
    "def get_embedder():\n",
    "    return get_registry().get(\"azure_openai\").create()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to check how to use and what you get back we have a test bellow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_0</th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_3062</th>\n",
       "      <th>dim_3063</th>\n",
       "      <th>dim_3064</th>\n",
       "      <th>dim_3065</th>\n",
       "      <th>dim_3066</th>\n",
       "      <th>dim_3067</th>\n",
       "      <th>dim_3068</th>\n",
       "      <th>dim_3069</th>\n",
       "      <th>dim_3070</th>\n",
       "      <th>dim_3071</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.002786</td>\n",
       "      <td>-0.022649</td>\n",
       "      <td>0.005107</td>\n",
       "      <td>0.026940</td>\n",
       "      <td>0.015299</td>\n",
       "      <td>0.009778</td>\n",
       "      <td>-0.005585</td>\n",
       "      <td>0.085468</td>\n",
       "      <td>0.011564</td>\n",
       "      <td>0.047623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001351</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>-0.017521</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.015119</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>-0.003605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.040522</td>\n",
       "      <td>-0.031269</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.023705</td>\n",
       "      <td>-0.010782</td>\n",
       "      <td>0.034536</td>\n",
       "      <td>0.012536</td>\n",
       "      <td>0.066818</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.025910</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004800</td>\n",
       "      <td>0.036563</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>0.005443</td>\n",
       "      <td>-0.023126</td>\n",
       "      <td>-0.002327</td>\n",
       "      <td>-0.003080</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>0.001872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 3072 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dim_0     dim_1     dim_2     dim_3     dim_4     dim_5     dim_6  \\\n",
       "0 -0.002786 -0.022649  0.005107  0.026940  0.015299  0.009778 -0.005585   \n",
       "1 -0.040522 -0.031269  0.004365  0.023705 -0.010782  0.034536  0.012536   \n",
       "\n",
       "      dim_7     dim_8     dim_9  ...  dim_3062  dim_3063  dim_3064  dim_3065  \\\n",
       "0  0.085468  0.011564  0.047623  ... -0.001351  0.007141 -0.017521  0.003406   \n",
       "1  0.066818  0.004377  0.025910  ... -0.004800  0.036563  0.008642  0.005443   \n",
       "\n",
       "   dim_3066  dim_3067  dim_3068  dim_3069  dim_3070  dim_3071  \n",
       "0  0.003008  0.002577  0.001279  0.015119  0.001032 -0.003605  \n",
       "1 -0.023126 -0.002327 -0.003080  0.001875  0.012593  0.001872  \n",
       "\n",
       "[2 rows x 3072 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate embeddings for a list of texts TEST\n",
    "\n",
    "embeddings = embedder.generate_embeddings([\"hello world\", \"goodbye world\"])\n",
    "# Convert embeddings into a pandas DataFrame\n",
    "embeddings_df = pd.DataFrame(\n",
    "    embeddings, columns=[f\"dim_{i}\" for i in range(len(embeddings[0]))])\n",
    "embeddings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "we need them to store the data in the tables. it checks if the data is valid and if it is not it will throw an error.\n",
    "\n",
    "the important one was the vector dimensions. lance db will block you if you try to store a vector with a different dimension than the one you have specified when creating the table.\n",
    "\n",
    "this means if we move to a different model we might have to change the table. possibly recreate it.\n",
    "\n",
    "!!! note\n",
    "for some reason lancedb couldnt accecpt a pydantic model with a list of dictionaries. so we had to use a list of strings instead.\n",
    "\n",
    "    also how you handle dictionaries is they have to be provided as a BaseModel. so you have to create a model for the dictionary and then use that model in the main model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(LanceModel):\n",
    "    email: str\n",
    "    name: str = embedder.SourceField()\n",
    "    # Embedding vector for semantic searches\n",
    "    vector: Vector(embedder.ndims()) = embedder.VectorField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nest_asyncio.apply()\n",
    "def get_lance_db_azure_credentials(credentials: DefaultAzureCredential = DefaultAzureCredential()):\n",
    "    return {\n",
    "        \"azure_storage_account_name\": \"some_account_name\",\n",
    "        \"azure_tenant_id\": \"some_tenant_id\",\n",
    "        \"azure_storage_token\": credentials.get_token(\n",
    "            \"https://storage.azure.com/.default\"\n",
    "        ).token,\n",
    "    }\n",
    "\n",
    "\n",
    "class LanceDBManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        database_url: str = \"az://dev-vector-db/\",\n",
    "        azure_credentials: Dict[str, Any] = get_lance_db_azure_credentials(),\n",
    "        embedder: TextEmbeddingFunction = embedder,\n",
    "        async_mode: bool = True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize LanceDBManager with the database URL, Azure credentials, and an embedder.\n",
    "\n",
    "        Args:\n",
    "            database_url (str): The path or URL to the LanceDB database.\n",
    "            azure_credentials (dict): Azure storage credentials.\n",
    "            embedder (TextEmbeddingFunction): Embedder instance for generating embeddings.\n",
    "        \"\"\"\n",
    "        self.database_url = database_url\n",
    "        self.azure_credentials = azure_credentials\n",
    "        self.embedder = embedder\n",
    "        self.async_mode = async_mode\n",
    "\n",
    "    def get_sync_manager(self):\n",
    "        return lancedb.connect(self.database_url, storage_options=self.azure_credentials)\n",
    "\n",
    "    @property\n",
    "    async def connection(self):\n",
    "        \"\"\"\n",
    "        Establish a connection to the LanceDB database.\n",
    "\n",
    "        Returns:\n",
    "            An asynchronous connection object to LanceDB.\n",
    "        \"\"\"\n",
    "        import lancedb\n",
    "\n",
    "        return await lancedb.connect_async(\n",
    "            uri=self.database_url,\n",
    "            storage_options=self.azure_credentials\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    async def table_names(self):\n",
    "        \"\"\"\n",
    "        Retrieve a list of table names in the database.\n",
    "\n",
    "        Returns:\n",
    "            List of table names.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            connection = await self.connection\n",
    "            return await connection.table_names()\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "    async def get_table(self, table_name: str):\n",
    "        \"\"\"\n",
    "        Get a table object from the database.\n",
    "\n",
    "        Args:\n",
    "            table_name (str): Name of the table to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            Table: LanceDB table object.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            connection = await self.connection\n",
    "            return await connection.open_table(table_name)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error getting table '{table_name}': {e}\")\n",
    "            raise\n",
    "\n",
    "    async def create_schema(self, table_name: str, schema: Any):\n",
    "        \"\"\"\n",
    "        Create a schema-based table in LanceDB.\n",
    "\n",
    "        Args:\n",
    "            table_name (str): Name of the table.\n",
    "            schema (Any): Schema of the table.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            connection = await self.connection\n",
    "            table = await connection.create_table(\n",
    "                table_name, schema=schema, exist_ok=True\n",
    "            )\n",
    "\n",
    "            # Example: Adding sample data for testing\n",
    "            sample_data = [{\"text\": \"hello world\"}, {\"text\": \"goodbye world\"}]\n",
    "            existing_rows = await table.to_pandas()\n",
    "            existing_texts = (\n",
    "                set(existing_rows[\"text\"]\n",
    "                    ) if \"text\" in existing_rows.columns else set()\n",
    "            )\n",
    "\n",
    "            # Avoid adding duplicates\n",
    "            new_data = [row for row in sample_data if row[\"text\"]\n",
    "                        not in existing_texts]\n",
    "            if new_data:\n",
    "                await table.add(new_data)\n",
    "\n",
    "            query = \"greetings\"\n",
    "            results = await self.vector_search(table_name, query)\n",
    "            print(f\"Search results for query '{query}': {results}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error creating schema for table '{\n",
    "                          table_name}': {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "    async def create_table(self, table_name: str, schema: Any, overwrite: bool = False):\n",
    "        \"\"\"\n",
    "        Create a new table in LanceDB.\n",
    "\n",
    "        Args:\n",
    "            table_name (str): Name of the table.\n",
    "            schema (Any): Schema of the table.\n",
    "            overwrite (bool): Whether to overwrite the table if it exists.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            connection = await self.connection\n",
    "            mode = \"overwrite\" if overwrite else \"create\"\n",
    "            await connection.create_table(table_name, schema=schema, mode=mode)\n",
    "            logging.info(f\"Table '{table_name}' created successfully.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error creating table '{table_name}': {e}\")\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "    async def add_data(\n",
    "        self, table_name: str, data: List[Dict[str, Any]], unique_field: str\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Add data to a LanceDB table, avoiding duplicates based on specified unique fields.\n",
    "\n",
    "        Args:\n",
    "            table_name (str): Name of the table.\n",
    "            data (List[Dict[str, Any]]): List of data entries to add.\n",
    "            unique_fields (List[str]): List of fields to use for uniqueness checks.\n",
    "\n",
    "        Returns:\n",
    "            int: Number of rows added.\n",
    "        \"\"\"\n",
    "        if not unique_field:\n",
    "            raise ValueError(\n",
    "                \"Unique field must be specified to check for duplicates.\")\n",
    "\n",
    "        try:\n",
    "            connection = await self.connection\n",
    "            async_table = await connection.open_table(table_name)\n",
    "\n",
    "            # The merge_insert function fails if the table is empty\n",
    "            if await async_table.count_rows() == 0:\n",
    "                await async_table.add(data)\n",
    "                logging.info(f\"Added {len(data)} entries to table '{\n",
    "                             table_name}'.\")\n",
    "                return len(data)\n",
    "\n",
    "            else:\n",
    "                rows_before = await async_table.count_rows()\n",
    "                await async_table.merge_insert(on=unique_field).when_not_matched_insert_all().execute(data)\n",
    "                rows_after = await async_table.count_rows()\n",
    "                new_rows = rows_after - rows_before\n",
    "                logging.info(f\"Added {new_rows} new entries to table '{\n",
    "                             table_name}'.\")\n",
    "            return new_rows\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error adding data to table '{table_name}': {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "    async def update_data(\n",
    "        self, table_name: str, data: List[Dict[str, Any]], unique_field: str\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Update data in a LanceDB table based on specified unique fields. Using the merge_insert with the when_matched_update_all() function\n",
    "        \"\"\"\n",
    "        if not unique_field:\n",
    "            raise ValueError(\n",
    "                \"Unique field must be specified to check for duplicates.\")\n",
    "\n",
    "        try:\n",
    "            connection = await self.connection\n",
    "            async_table = await connection.open_table(table_name)\n",
    "\n",
    "            if await async_table.count_rows() == 0:\n",
    "                await async_table.add(data)\n",
    "                logging.info(f\"Added {len(data)} entries to table '{\n",
    "                             table_name}'.\")\n",
    "                return len(data)\n",
    "\n",
    "            else:\n",
    "                await async_table.merge_insert(on=unique_field).when_matched_update_all().execute(data)\n",
    "                logging.info(f\"Updated {len(data)} entries in table '{\n",
    "                             table_name}'.\")\n",
    "                return len(data)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error updating data in table '{table_name}': {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "    async def fetch_data(\n",
    "        self,\n",
    "        table_name: str,\n",
    "        as_pandas: bool = True,\n",
    "        page: int = 1,\n",
    "        per_page: int = 10,\n",
    "        filter: str = None,\n",
    "        columns_to_exclude: List[str] = [],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Fetch data from a LanceDB table with pagination and optional filtering.\n",
    "\n",
    "        Args:\n",
    "            table_name (str): Name of the table.\n",
    "            as_pandas (bool): Whether to return data as a pandas DataFrame.\n",
    "            page (int): Page number for pagination.\n",
    "            per_page (int): Number of items per page. Use -1 to fetch all data.\n",
    "            filter (str): SQL filter expression. these are the filters that can be used - https://lancedb.github.io/lancedb/sql/#sql-filters\n",
    "            columns_to_exclude (List[str]): List of columns to exclude from the results.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame or List[Dict]: Fetched data.\n",
    "            List[Dict]: Fetched data as a list of dictionaries if as_pandas is set to False.\n",
    "        \"\"\"\n",
    "        # docs used to make this function: https://lancedb.github.io/lancedb/sql/#pre-and-post-filtering\n",
    "        try:\n",
    "            connection = await self.connection\n",
    "            async_table = await connection.open_table(table_name)\n",
    "            query = async_table.query()\n",
    "\n",
    "            # dont include the vector column in the results .select([\"title\", \"text\", \"_distance\"]) is used to define the columns to be returned\n",
    "            # !DANGER The paranthesis around async_table.to_pandas() is used to make sure that the head function is called on the dataframe and not coroutine\n",
    "            table_df = (await async_table.to_pandas()).head(1).columns\n",
    "\n",
    "            columns_to_include = [\n",
    "                col for col in table_df if col not in columns_to_exclude\n",
    "            ]\n",
    "\n",
    "            query = query.select(columns_to_include).with_row_id()\n",
    "\n",
    "            # the \"await async_table.count_rows()\" is done like that beacause there is a bug in lancedb v0.17.0 that does not respect the limit(-1) when used with where clause\n",
    "            # https://github.com/lancedb/lancedb/issues/1852\n",
    "            if filter:\n",
    "                query = (\n",
    "                    query.where(filter).limit(\n",
    "                        per_page).offset((page - 1) * per_page)\n",
    "                    if per_page != -1\n",
    "                    else query.where(filter).limit(await async_table.count_rows())\n",
    "                )\n",
    "            else:\n",
    "                query = (\n",
    "                    query.limit(per_page).offset((page - 1) * per_page)\n",
    "                    if per_page != -1\n",
    "                    else query.limit(await async_table.count_rows())\n",
    "                )\n",
    "            df = await query.to_pandas()\n",
    "            return df if as_pandas else df.to_dict(orient=\"records\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching data from table '{\n",
    "                          table_name}': {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "    async def vector_search(\n",
    "        self,\n",
    "        table_name: str,\n",
    "        query: str,\n",
    "        limit: int = 5,\n",
    "        as_pandas: bool = True,\n",
    "        columns_to_exclude: List[str] = [],\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Perform a vector search on a LanceDB table.\n",
    "\n",
    "        Args:\n",
    "            table_name (str): Name of the table.\n",
    "            query (str): Query text to search for.\n",
    "            limit (int): Number of search results to return.\n",
    "            as_pandas (bool): Whether to return data as a pandas DataFrame.\n",
    "            columns_to_exclude (List[str]): List of columns to exclude from the results.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: Search results.\n",
    "            List[Dict]: Search results as a list of dictionaries. if as_pandas is set to False\n",
    "        \"\"\"\n",
    "        try:\n",
    "            connection = await self.connection\n",
    "            async_table = await connection.open_table(table_name)\n",
    "\n",
    "            # dont include the vector column in the results .select([\"title\", \"text\", \"_distance\"]) is used to define the columns to be returned\n",
    "            # !DANGER The paranthesis around async_table.to_pandas() is used to make sure that the head function is called on the dataframe and not coroutine\n",
    "            table_df = (await async_table.to_pandas()).head(3).columns\n",
    "\n",
    "            columns_to_include = [\n",
    "                col for col in table_df if col not in columns_to_exclude\n",
    "            ]\n",
    "\n",
    "            # Generate embedding for the query\n",
    "            embedding = self.embedder.generate_embeddings([query])[0]\n",
    "\n",
    "            # Perform vector search\n",
    "            # results = await async_table.vector_search(embedding).limit(limit).to_pandas()\n",
    "            results = (\n",
    "                await async_table.query()\n",
    "                .select(columns_to_include)\n",
    "                .with_row_id()\n",
    "                .nearest_to(embedding)\n",
    "                .limit(limit)\n",
    "                .to_pandas()\n",
    "            )\n",
    "\n",
    "            return results if as_pandas else results.to_dict(orient=\"records\")\n",
    "        except Exception as e:\n",
    "            logging.error(\n",
    "                f\"Error performing vector search on table '{table_name}': {e}\"\n",
    "            )\n",
    "            raise\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "    async def delete_table(self, table_name: str):\n",
    "        \"\"\"\n",
    "        Delete a table from LanceDB.\n",
    "\n",
    "        Args:\n",
    "            table_name (str): Name of the table to delete.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            connection = await self.connection\n",
    "            await connection.drop_table(table_name)\n",
    "            logging.info(f\"Table '{table_name}' deleted successfully.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error deleting table '{table_name}': {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "    async def delete_rows(self, table_name: str, condition: str):\n",
    "        \"\"\"\n",
    "        Delete rows from a table based on a condition.\n",
    "\n",
    "        Args:\n",
    "            table_name (str): Name of the table.\n",
    "            condition (str): Condition to match rows for deletion.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            connection = await self.connection\n",
    "            async_table = await connection.open_table(table_name)\n",
    "            await async_table.delete(where=condition)\n",
    "            logging.info(\n",
    "                f\"Rows matching condition '{condition}' deleted from table '{\n",
    "                    table_name\n",
    "                }'.\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error deleting rows from table '{\n",
    "                          table_name}': {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "    async def delete_duplicates(self, table_name: str, subset: List[str]):\n",
    "        \"\"\"\n",
    "        Remove duplicate rows from a LanceDB table based on specified columns.\n",
    "\n",
    "        Args:\n",
    "            table_name (str): Name of the table.\n",
    "            subset (List[str]): List of column names to check for duplicates.\n",
    "\n",
    "        Returns:\n",
    "            int: Number of duplicate rows removed.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            connection = await self.connection\n",
    "            async_table = await connection.open_table(table_name)\n",
    "\n",
    "            # Fetch the table's data\n",
    "            df = await async_table.to_pandas()\n",
    "\n",
    "            # Drop duplicates based on the specified subset\n",
    "            df_unique = df.drop_duplicates(subset=subset)\n",
    "            duplicates_removed = len(df) - len(df_unique)\n",
    "\n",
    "            if duplicates_removed > 0:\n",
    "                # Overwrite the table with the unique data\n",
    "                await async_table.add(\n",
    "                    df_unique.to_dict(orient=\"records\"), mode=\"overwrite\"\n",
    "                )\n",
    "                logging.info(\n",
    "                    f\"Removed {duplicates_removed} duplicate rows from table '{\n",
    "                        table_name\n",
    "                    }'.\"\n",
    "                )\n",
    "            else:\n",
    "                logging.info(f\"No duplicates found in table '{table_name}'.\")\n",
    "\n",
    "            return duplicates_removed\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error deleting duplicates from table '{\n",
    "                          table_name}': {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage\n",
    "\n",
    "below is an example of how to use the manager. the manager will use the embedder to interact with the tables.\n",
    "\n",
    "- credentials and initialisation\n",
    "- create a table\n",
    "  - will silently fail if the table already exists\n",
    "- make the data fit the model\n",
    "- insert the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!! Danger !!! Delete all tables the lancedb database\n",
    "\n",
    "This deletes all the tables in the database. This is a dangerous operation and should only be used in development environments.\n",
    "\n",
    "- keep it commented out in in commit history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "async def delete_db_schema():\n",
    "    credentials = DefaultAzureCredential()\n",
    "    azure_credentials = {\n",
    "        \"azure_storage_account_name\": \"some_storage_account_name\",\n",
    "        \"azure_tenant_id\": \"some_tenant_id\",\n",
    "        \"azure_storage_token\": credentials.get_token(\"https://storage.azure.com/.default\").token,\n",
    "    }\n",
    "    database_url = \"az://dev-vector-db/\"\n",
    "    db_manager = LanceDBManager(database_url=database_url)\n",
    "\n",
    "    deleted_user = await db_manager.delete_table(\"user\")\n",
    "    print(deleted_user)\n",
    "\n",
    "await delete_db_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create all tables the lancedb database\n",
    "\n",
    "uses the model to create all the tables in the database. it will silently fail if the table already exists.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error creating table 'user': Table 'user' already exists\n",
      "ERROR:root:Error creating table 'labels': Table 'labels' already exists\n",
      "ERROR:root:Error creating table 'content_labels': Table 'content_labels' already exists\n"
     ]
    }
   ],
   "source": [
    "async def create_db():\n",
    "    \"\"\"\n",
    "    Create the database schema for the local news AI application\n",
    "    \"\"\"\n",
    "    # Initialize manager\n",
    "    database_url = \"az://dev-vector-db/\"\n",
    "    # Use default database URL and Azure credentials and embedder\n",
    "    manager = LanceDBManager(database_url=database_url)\n",
    "    # Create tables\n",
    "    await manager.create_table(\"user\", User)\n",
    "await create_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add data to all current tables the lancedb database\n",
    "\n",
    "example on how data is added to the tables.\n",
    "\n",
    "it adds fake data to the tables.\n",
    "\n",
    "## ways to do it\n",
    "\n",
    "- you could add the data and type check it before adding it to the database manually, as well and making the embedding manually\n",
    "  - make sure they are the same dimention embedding\n",
    "- you could just send the array to the database and let it handle the type checking and embedding\n",
    "  - there are some fields in the embeddings pydantic model which are defined to be the embeddings.SourceField()\n",
    "  - TODO: check if we can have more than 1 source field in the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 14.94it/s]\n",
      "100%|██████████| 23/23 [00:00<00:00, 62117.83it/s]\n"
     ]
    }
   ],
   "source": [
    "async def add_db_schema():\n",
    "    \"\"\"\n",
    "    Adds sample data to 'user', 'content', 'labels', and 'content_labels' tables using raw data and dynamically generates vectors.\n",
    "    \"\"\"\n",
    "    credentials = DefaultAzureCredential()\n",
    "    azure_credentials = {\n",
    "        \"azure_storage_account_name\": \"some_storage_account_name\",\n",
    "        \"azure_tenant_id\": \"some_tenant_id\",\n",
    "        \"azure_storage_token\": credentials.get_token(\"https://storage.azure.com/.default\").token,\n",
    "    }\n",
    "    database_url = \"az://dev-vector-db/\"\n",
    "    db_manager = LanceDBManager(\n",
    "        database_url=database_url, azure_credentials=azure_credentials)\n",
    "    # Raw data to be added to the 'user' table\n",
    "    more_user_data = [\n",
    "        {\"email\": \"lancedb@viewer.com\", \"username\": \"Lance Vine\",},\n",
    "    ]\n",
    "\n",
    "    # Convert raw data to model instances and dynamically generate vectors for the 'query' field\n",
    "    validated_users = []\n",
    "    for data in tqdm(more_user_data):\n",
    "        data[\"user_id\"] = hashlib.sha256(\n",
    "                    (data[\"usename\"] + data[\"email\"]).encode('utf-8')).hexdigest()\n",
    "        data[\"vector\"] = embedder.generate_embeddings(\n",
    "            [data[\"username\"]])  # Generate the embedding for the query\n",
    "        validated_users.append(User(**data))\n",
    "\n",
    "    # Add user data to database\n",
    "    await db_manager.add_data(\"user\", more_user_data, unique_field=\"user_id\")\n",
    "\n",
    "\n",
    "# Run the schema setup function\n",
    "asyncio.run(add_db_schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data\n",
    "\n",
    "example on how data is fetched from the tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_all_data():\n",
    "    # Use default database URL and Azure credentials and embedder\n",
    "    db_manager = LanceDBManager()\n",
    "    # Fetch data from 'user' table\n",
    "    user_df = await db_manager.fetch_data(\"user\")\n",
    "    return user_df\n",
    "\n",
    "# Run the async functions\n",
    "user_df = await fetch_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>name</th>\n",
       "      <th>query</th>\n",
       "      <th>vector</th>\n",
       "      <th>newsletter</th>\n",
       "      <th>sources</th>\n",
       "      <th>saved_content</th>\n",
       "      <th>_rowid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [email, name, query, vector, newsletter, sources, saved_content, _rowid]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector search\n",
    "\n",
    "find the most similar vectors in the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def vector_search_data():\n",
    "    # Use default database URL and Azure credentials and embedder\n",
    "    db_manager = LanceDBManager()\n",
    "\n",
    "    # Perform a vector search\n",
    "    results = await db_manager.vector_search(\"user\", query=\"Vance\", limit=50)\n",
    "    print(\"Search Results:\", results)\n",
    "await vector_search_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
